# EmojiClassifier
Emojis and avatars are used to convey nonverbal cues. These indications have become an integral aspect of online conversation, product reviews, brand sentiment, and other activities. It also resulted in increased data science research into emoji-driven storytelling.

With advances in computer vision and deep learning, it is now possible to discern human emotions through photographs. This deep learning experiment uses human facial emotions to filter and map emojis or avatars by building a convolution neural network architecture and training the model on the FER2013 dataset.

## Dataset

The FER2013 dataset (facial expression recognition) consists of 48*48 pixel grayscale face images. The images are centered and occupy an equal amount of space. The training set consists of 28,709 examples and the public test set consists of 3,589 examples. This dataset consist of facial emotions of following categories:

0: angry
1: disgust
2: fear
3: happy
4: sad
5: surprise
6: natural

The dataset can be found [here](https://www.kaggle.com/datasets/msambare/fer2013).


